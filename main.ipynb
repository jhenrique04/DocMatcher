{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_reader import PDFReader\n",
    "from preprocessor import Preprocessor\n",
    "from bert_model import BertModel\n",
    "from analyzer import Analyzer\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_vec(words, model):\n",
    "    vectors = [model[word] for word in words if word in model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "\n",
    "def process_documents(document_paths, pdf_reader, preprocessor, bert_model, word2vec_model):\n",
    "    document_analyses = []\n",
    "    embeddings = []\n",
    "\n",
    "    for path in document_paths:\n",
    "        text = pdf_reader.extract_text(path)\n",
    "        processed_text = preprocessor.process(text)\n",
    "\n",
    "        # Detailed analisys\n",
    "        analysis_details = preprocessor.analyze_details(processed_text)\n",
    "        complexity_score = preprocessor.analyze_complexity(processed_text)\n",
    "        style_score = preprocessor.analyze_style(processed_text)\n",
    "        vocabulary_diversity = preprocessor.analyze_vocabulary(processed_text)\n",
    "\n",
    "        # Extract key-terms\n",
    "        key_terms = preprocessor.extract_key_terms(processed_text)\n",
    "\n",
    "        # Calculate topics\n",
    "        topics = preprocessor.analyze_topics(processed_text)\n",
    "\n",
    "        analysis = {\n",
    "            \"details\": analysis_details,\n",
    "            \"complexity\": complexity_score,\n",
    "            \"style\": style_score,\n",
    "            \"vocabulary_diversity\": vocabulary_diversity,\n",
    "            \"key_terms\": key_terms,\n",
    "            \"topics\": topics\n",
    "        }\n",
    "\n",
    "        bert_embedding = bert_model.get_embeddings(processed_text)\n",
    "        w2v_embedding = document_to_vec(processed_text, word2vec_model)\n",
    "        combined_embedding = torch.from_numpy(np.concatenate((bert_embedding.detach().numpy(), w2v_embedding)))\n",
    "        \n",
    "        embeddings.append(combined_embedding)\n",
    "        document_analyses.append((path, analysis))\n",
    "\n",
    "    return embeddings, document_analyses\n",
    "\n",
    "\n",
    "def generate_feedback(test_embedding, train_embeddings):\n",
    "    distances = [torch.dist(test_embedding, train_emb, 2).item() for train_emb in train_embeddings]\n",
    "    avg_distance = sum(distances) / len(distances)\n",
    "    if avg_distance > 0.21:\n",
    "        return \"O documento pode ser melhorado em [aspecto específico].\"\n",
    "    else:\n",
    "        return \"O documento está alinhado com os padrões de treino.\"\n",
    "\n",
    "\n",
    "def get_document_paths(directory):\n",
    "    doc_names = [filename for filename in os.listdir(directory) if filename.endswith('.pdf')]\n",
    "    file_paths = [os.path.join(directory, filename) for filename in doc_names]\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def calculate_benchmarks(train_analyses):\n",
    "    # Calculating averages and standard deviations\n",
    "    sentiment_scores = [analysis['details']['sentiment']['compound'] for _, analysis in train_analyses]\n",
    "    num_sentences = [analysis['details']['num_sentences'] for _, analysis in train_analyses]\n",
    "\n",
    "    avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
    "    std_sentiment = np.std(sentiment_scores)\n",
    "    avg_num_sentences = sum(num_sentences) / len(num_sentences)\n",
    "    std_num_sentences = np.std(num_sentences)\n",
    "\n",
    "    return {\n",
    "        \"avg_sentiment\": avg_sentiment,\n",
    "        \"std_sentiment\": std_sentiment,\n",
    "        \"avg_num_sentences\": avg_num_sentences,\n",
    "        \"std_num_sentences\": std_num_sentences\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    pdf_reader = PDFReader()\n",
    "    preprocessor = Preprocessor()\n",
    "    bert_model = BertModel('./finetuned_model')\n",
    "    analyzer = Analyzer()\n",
    "    word2vec_model = KeyedVectors.load_word2vec_format('word2Vec_models/cbow_s1000.txt', binary=False)\n",
    "\n",
    "    train_doc_paths = get_document_paths('train/')\n",
    "    test_doc_paths = get_document_paths('test/')\n",
    "    \n",
    "    train_embeddings, train_analyses = process_documents(train_doc_paths, pdf_reader, preprocessor, bert_model, word2vec_model)\n",
    "    test_embeddings, test_analyses = process_documents(test_doc_paths, pdf_reader, preprocessor, bert_model, word2vec_model)\n",
    "\n",
    "    benchmarks = calculate_benchmarks(train_analyses)\n",
    "\n",
    "    for test_embedding, test_analysis in zip(test_embeddings, test_analyses):\n",
    "        test_path = test_analysis[0]  # Doc path\n",
    "        analysis_data = test_analysis[1]\n",
    "\n",
    "        # Euclidian distance\n",
    "        avg_distance = analyzer.average_distance_to_train_docs(test_embedding, train_embeddings)\n",
    "        print(f\"Documento: {test_path}, Distância média para documentos de treino = {avg_distance:.3f}\")\n",
    "\n",
    "        # Similarity analisys\n",
    "        analysis_result = analyzer.analyze(test_embedding, train_embeddings)\n",
    "        print(f\"Documento: {test_path}, Média da similaridade por cosseno: {analysis_result['average_similarity']:.3f}\")\n",
    "\n",
    "        # Embedding-based feedback\n",
    "        feedback = generate_feedback(test_embedding, train_embeddings)\n",
    "\n",
    "        # Detailed-analisys feedback\n",
    "        detailed_feedback = f\"Análise Detalhada: Sentimento - {analysis_data['details']['sentiment']}, Número de Frases - {analysis_data['details']['num_sentences']}\"\n",
    "        feedback += f\"\\n{detailed_feedback}\"\n",
    "\n",
    "        # Compare benchmarks and add feedbacks\n",
    "        sentiment_diff = analysis_data['details']['sentiment']['compound'] - benchmarks['avg_sentiment']\n",
    "        num_sentences_diff = analysis_data['details']['num_sentences'] - benchmarks['avg_num_sentences']\n",
    "\n",
    "        if abs(sentiment_diff) > benchmarks['std_sentiment']:\n",
    "            feedback += f\"\\nO sentimento deste documento é significativamente {'positivo' if sentiment_diff > 0 else 'negativo'} em comparação com os documentos de treino.\"\n",
    "        if abs(num_sentences_diff) > benchmarks['std_num_sentences']:\n",
    "            feedback += f\"\\nEste documento tem {'mais' if num_sentences_diff > 0 else 'menos'} frases do que a média dos documentos de treino.\"\n",
    "\n",
    "        # Add new feedbacks based on the analysis\n",
    "        feedback += f\"\\nComplexidade do Texto (Flesch-Kincaid): {analysis_data['complexity']}\"\n",
    "        feedback += f\"\\nEstilo de Escrita: {'Passiva' if analysis_data['style'] > 0 else 'Ativa'}\"\n",
    "        feedback += f\"\\nDiversidade de Vocabulário: {analysis_data['vocabulary_diversity']:.2f}\"\n",
    "        feedback += f\"\\nTermos-chave identificados: {', '.join(analysis_data['key_terms'])}\"\n",
    "        feedback += f\"\\nTópicos principais: {', '.join(analysis_data['topics'])}\"\n",
    "\n",
    "\n",
    "        # Print final feedback\n",
    "        print(f\"Documento: {test_path}, Feedback Final: {feedback}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento: test/risk.pdf, Distância média para documentos de treino = 0.246\n",
      "Documento: test/risk.pdf, Média da similaridade por cosseno: 0.953\n",
      "Documento: test/risk.pdf, Feedback Final: O documento pode ser melhorado em [aspecto específico].\n",
      "Análise Detalhada: Sentimento - {'neg': 0.001, 'neu': 0.988, 'pos': 0.011, 'compound': 0.9898}, Número de Frases - 552\n",
      "Complexidade do Texto (Flesch-Kincaid): 27.3\n",
      "Estilo de Escrita: Ativa\n",
      "Diversidade de Vocabulário: 0.26\n",
      "Termos-chave identificados: risco\n",
      "Tópicos principais: risco, empresa, Riscos, Governança, evidenciação\n",
      "\n",
      "Documento: test/politicaSegurancaInformacao.pdf, Distância média para documentos de treino = 0.207\n",
      "Documento: test/politicaSegurancaInformacao.pdf, Média da similaridade por cosseno: 0.958\n",
      "Documento: test/politicaSegurancaInformacao.pdf, Feedback Final: O documento está alinhado com os padrões de treino.\n",
      "Análise Detalhada: Sentimento - {'neg': 0.007, 'neu': 0.986, 'pos': 0.007, 'compound': -0.3182}, Número de Frases - 133\n",
      "O sentimento deste documento é significativamente negativo em comparação com os documentos de treino.\n",
      "Complexidade do Texto (Flesch-Kincaid): 89.3\n",
      "Estilo de Escrita: Ativa\n",
      "Diversidade de Vocabulário: 0.40\n",
      "Termos-chave identificados: ataque, criptografia, risco, segurança, vulnerabilidade\n",
      "Tópicos principais: Segurança, informação, Informação, Banco, PACCAR\n",
      "\n",
      "Documento: test/risk2.pdf, Distância média para documentos de treino = 0.212\n",
      "Documento: test/risk2.pdf, Média da similaridade por cosseno: 0.960\n",
      "Documento: test/risk2.pdf, Feedback Final: O documento pode ser melhorado em [aspecto específico].\n",
      "Análise Detalhada: Sentimento - {'neg': 0.007, 'neu': 0.988, 'pos': 0.005, 'compound': -0.2577}, Número de Frases - 359\n",
      "O sentimento deste documento é significativamente negativo em comparação com os documentos de treino.\n",
      "Complexidade do Texto (Flesch-Kincaid): 192.7\n",
      "Estilo de Escrita: Ativa\n",
      "Diversidade de Vocabulário: 0.31\n",
      "Termos-chave identificados: vulnerabilidade, risco, segurança\n",
      "Tópicos principais: risco, Modal, controle, processo, gerenciamento\n",
      "\n",
      "Documento: test/politicaSegurancaInformacao2.pdf, Distância média para documentos de treino = 0.218\n",
      "Documento: test/politicaSegurancaInformacao2.pdf, Média da similaridade por cosseno: 0.959\n",
      "Documento: test/politicaSegurancaInformacao2.pdf, Feedback Final: O documento pode ser melhorado em [aspecto específico].\n",
      "Análise Detalhada: Sentimento - {'neg': 0.004, 'neu': 0.991, 'pos': 0.005, 'compound': -0.2263}, Número de Frases - 89\n",
      "O sentimento deste documento é significativamente negativo em comparação com os documentos de treino.\n",
      "Complexidade do Texto (Flesch-Kincaid): 45.3\n",
      "Estilo de Escrita: Ativa\n",
      "Diversidade de Vocabulário: 0.44\n",
      "Termos-chave identificados: vulnerabilidade, ataque, risco, segurança\n",
      "Tópicos principais: Segurança, Informação, informação, acesso, segurança\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
